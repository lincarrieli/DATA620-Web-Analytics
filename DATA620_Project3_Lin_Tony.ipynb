{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA 620 Project 3\n",
    "\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "\n",
    "Project is due 4/11.\n",
    "\n",
    "Source: Natural Language Processing with Python, exercise 6.10.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "import pandas as pd\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk import DecisionTreeClassifier\n",
    "from nltk import classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the names data\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "        [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender features with NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'd'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gender feature returns the last word of name\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}\n",
    "gender_features('David')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the features\n",
    "featuresets = [(gender_features(n), g) for (n,g) in names]\n",
    "\n",
    "# split data to train and test sets\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "\n",
    "# train a Naive Bayes classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Bridget'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\n"
     ]
    }
   ],
   "source": [
    "# evaluate the classifier\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     33.2 : 1.0\n",
      "             last_letter = 'k'              male : female =     31.6 : 1.0\n",
      "             last_letter = 'f'              male : female =     14.8 : 1.0\n",
      "             last_letter = 'p'              male : female =     12.0 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# get the most informative gender features\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use apply_features() to return a generator\n",
    "from nltk.classify import apply_features\n",
    "train_set = apply_features(gender_features, names[500:])\n",
    "test_set = apply_features(gender_features, names[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gender_features return first letter and last letter of name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'firstletter': 'j',\n",
       " 'lastletter': 'n',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 0,\n",
       " 'has(e)': False,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 1,\n",
       " 'has(h)': True,\n",
       " 'count(i)': 0,\n",
       " 'has(i)': False,\n",
       " 'count(j)': 1,\n",
       " 'has(j)': True,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features\n",
    "gender_features2('John')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features2(n), g) for (n,g) in names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500 6944 7944\n"
     ]
    }
   ],
   "source": [
    "# split data to train, dev, and test set\n",
    "train_names = names[1000:]\n",
    "devtest_names = names[500:1000]\n",
    "test_names = names[:500]\n",
    "\n",
    "print(len(test_names), len(devtest_names), len(train_names), len(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having divided the corpus into appropriate datasets, we train a model using the training\n",
    "set , and then run it on the dev-test set ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features(n), g) for (n,g) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the dev-test set, we can generate a list of the errors that the classifier makes when\n",
    "predicting name genders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append( (tag, guess, name) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then examine individual error cases where the model predicted the wrong label,\n",
    "and try to determine what additional pieces of information would allow it to make the\n",
    "right decision (or which existing pieces of information are tricking it into making the\n",
    "wrong decision). The feature set can then be adjusted accordingly. The names classifier\n",
    "that we have built generates about 100 errors on the dev-test corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Adrian                        \n",
      "correct=female   guess=male     name=Annabell                      \n",
      "correct=female   guess=male     name=Austin                        \n"
     ]
    }
   ],
   "source": [
    "for (tag, guess, name) in sorted(errors)[:3]: # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n",
    "        print('correct=%-8s guess=%-8s name=%-30s' % (tag, guess, name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. gender_features : Last letter only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features(n), g) for (n,g) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development set accuracy = 0.758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test set accuracy = 0.744"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. gender_features : Last letter, First letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features2(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features2(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features2(n), g) for (n,g) in test_names]\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier2, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development set accuracy = 0.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742\n"
     ]
    }
   ],
   "source": [
    "#test_set\n",
    "print(nltk.classify.accuracy(classifier2, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set accuracy = 0.742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. gender_features : Last letter, Last two letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features3(word):\n",
    "    return {'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix1': 'k', 'suffix2': 'ek'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features3('Shrek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features3(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features3(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features3(n), g) for (n,g) in test_names]\n",
    "classifier3 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier3, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development set accuracy = 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764\n"
     ]
    }
   ],
   "source": [
    "#test_set\n",
    "print(nltk.classify.accuracy(classifier3, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set accuracy = 0.764"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. gender_features : First Letter, Last two letters, check last letter is vowel or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses first letter instead of last letter; keeps last vowel and last 2 char suffix\n",
    "def gender_features4(word):\n",
    "    return {'first_letter': word[0],\n",
    "            'suffix': word[-2:],\n",
    "            'last_is_vowel' : (word[-1] in 'aeiouy')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'S', 'suffix': 'ek', 'last_is_vowel': False}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features4('Shrek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features4(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features4(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features4(n), g) for (n,g) in test_names]\n",
    "classifier4 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier4, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development set accuracy = 0.776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier4, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set accuracy = 0.768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error testing with NBC with our best gender_features which is the gender_features2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Aubrey                        \n",
      "correct=female   guess=male     name=Beatriz                       \n",
      "correct=female   guess=male     name=Beilul                        \n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier2.classify(gender_features2(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, guess, name))\n",
    "\n",
    "for (tag, guess, name) in sorted(errors)[:3]:\n",
    "    print('correct=%-8s guess=%-8s name=%-30s' %(tag, guess, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. gender_features : Last letter only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features(n), g) for (n,g) in test_names]\n",
    "dtclassifier = nltk.classify.DecisionTreeClassifier.train(train_set, entropy_cutoff=0,support_cutoff=0)\n",
    "print(nltk.classify.accuracy(dtclassifier, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development set accuracy = 0.758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(dtclassifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set accuracy = 0.744"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. gender_features : Last letter, First letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features2(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features2(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features2(n), g) for (n,g) in test_names]\n",
    "dtclassifier2 = nltk.classify.DecisionTreeClassifier.train(train_set, entropy_cutoff=0,support_cutoff=0)\n",
    "print(nltk.classify.accuracy(dtclassifier2, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development set accuracy = 0.798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(dtclassifier2, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set accuracy = 0.778"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. gender_features : Last letter, Last two letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features3(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features3(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features3(n), g) for (n,g) in test_names]\n",
    "dtclassifier3 = nltk.classify.DecisionTreeClassifier.train(train_set, entropy_cutoff=0,support_cutoff=0)\n",
    "print(nltk.classify.accuracy(dtclassifier3, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development set accuracy = 0.792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(dtclassifier3, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set accuracy = 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. gender_features : First Letter, Last two letters, check last letter is vowel or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784\n"
     ]
    }
   ],
   "source": [
    "train_set = [(gender_features4(n), g) for (n,g) in train_names]\n",
    "devtest_set = [(gender_features4(n), g) for (n,g) in devtest_names]\n",
    "test_set = [(gender_features4(n), g) for (n,g) in test_names]\n",
    "dtclassifier4 = nltk.classify.DecisionTreeClassifier.train(train_set, entropy_cutoff=0,support_cutoff=0)\n",
    "print(nltk.classify.accuracy(dtclassifier4, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development set accuracy = 0.784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.764\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(dtclassifier4, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set accuracy = 0.764"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error testing with decisiontree with our best gender_features which is the gender_features2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Adrian                        \n",
      "correct=female   guess=male     name=Ashleigh                      \n",
      "correct=female   guess=male     name=Austin                        \n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = dtclassifier2.classify(gender_features2(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, guess, name))\n",
    "\n",
    "for (tag, guess, name) in sorted(errors)[:3]:\n",
    "    print('correct=%-8s guess=%-8s name=%-30s' %(tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
