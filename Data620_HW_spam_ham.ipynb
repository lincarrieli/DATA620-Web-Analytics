{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 620\n",
    "### Document Classification - Tony Mei and Lin Li\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Spambase\n",
    "\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Spam-ham file and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and read csv file\n",
    "url = \"https://raw.githubusercontent.com/lincarrieli/DATA620-Web-Analytics/main/SMSSpamCollection\"\n",
    "spam_df = pd.read_csv(url, sep='\\t', header = None)\n",
    "spam_df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column names\n",
    "spam_df.columns =['spam', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of rows and columns\n",
    "spam_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "spam_df.drop_duplicates(inplace = True)\n",
    "\n",
    "# Get new shape\n",
    "spam_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    0\n",
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missiong data\n",
    "spam_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use NLP to clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text (text):\n",
    "    # remove punctuation\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    # remove stopwords\n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply process_text function \n",
    "spam_df['text'].head().apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate vector for ML algorithms fro classification and predictions with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 11425)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create bag of words model and convert to token count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(analyzer = process_text)\n",
    "spam_bow = cv.fit_transform(spam_df['text'])\n",
    "\n",
    "# get shape of spam_bow\n",
    "spam_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_bow, spam_df['spam'], test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Naive Bayes classifier to train dataset\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' ... 'ham' 'spam' 'spam']\n",
      "['ham' 'ham' 'ham' ... 'ham' 'spam' 'spam']\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(X_train)\n",
    "print(pred)\n",
    "print(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      3620\n",
      "        spam       0.98      0.98      0.98       515\n",
      "\n",
      "    accuracy                           1.00      4135\n",
      "   macro avg       0.99      0.99      0.99      4135\n",
      "weighted avg       1.00      1.00      1.00      4135\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3612    8]\n",
      " [  12  503]]\n",
      "Accuracy:  0.9951632406287787\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on training dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "print(classification_report(y_train, pred))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_train, pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "\n",
    "# Get aaccuracy\n",
    "accu = accuracy_score(y_train, pred)\n",
    "print('Accuracy: ', accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n",
      "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "# Test model on test data\n",
    "pred = classifier.predict(X_test)\n",
    "print(pred)\n",
    "print(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.95      0.97       896\n",
      "        spam       0.75      0.93      0.83       138\n",
      "\n",
      "    accuracy                           0.95      1034\n",
      "   macro avg       0.87      0.94      0.90      1034\n",
      "weighted avg       0.96      0.95      0.95      1034\n",
      "\n",
      "Confusion Matrix: \n",
      " [[854  42]\n",
      " [  9 129]]\n",
      "Accuracy:  0.9506769825918762\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "\n",
    "# Get aaccuracy\n",
    "accu = accuracy_score(y_test, pred)\n",
    "print('Accuracy: ', accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Naive Bayes model predicted the testing dataset with accuracy of 95 %, slightly worse than its predictions with the training set, but still very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with spam messages\n",
    "\n",
    "I downloaded the Spam folder from my person gmail account, and use the model for spam predictions. This will allow us to evaluate the model with new set of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download spam mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailbox\n",
    "import email\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mbox path\n",
    "mbox = mailbox.mbox('Spam.mbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mbox.csv\", \"w\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    for message in mbox:\n",
    "        writer.writerow([message['subject'],message['X-Gmail-Labels']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_spam = pd.read_csv('mbox.csv', names=['subject', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"label\", \"subject\"]\n",
    "\n",
    "my_spam = my_spam.reindex(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spam,Category Updates,Unread</td>\n",
       "      <td>Amazing Sale! Get This Diet Product For a Huge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spam,Category Promotions,Unread</td>\n",
       "      <td>BUSINESS ASSISTANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spam,Category Promotions,Unread</td>\n",
       "      <td>April EcoQuest - Check for Cherries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spam,Category Updates,Unread</td>\n",
       "      <td>Walgreens still needs your input to improve pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spam,Category Promotions,Unread</td>\n",
       "      <td>Investigate suspicious activity on your account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             label  \\\n",
       "0     Spam,Category Updates,Unread   \n",
       "1  Spam,Category Promotions,Unread   \n",
       "2  Spam,Category Promotions,Unread   \n",
       "3     Spam,Category Updates,Unread   \n",
       "4  Spam,Category Promotions,Unread   \n",
       "\n",
       "                                             subject  \n",
       "0  Amazing Sale! Get This Diet Product For a Huge...  \n",
       "1                                BUSINESS ASSISTANCE  \n",
       "2                April EcoQuest - Check for Cherries  \n",
       "3  Walgreens still needs your input to improve pr...  \n",
       "4    Investigate suspicious activity on your account  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Amazing, Sale, Get, Diet, Product, Huge, Disc...\n",
       "1                               [BUSINESS, ASSISTANCE]\n",
       "2                   [April, EcoQuest, Check, Cherries]\n",
       "3    [Walgreens, still, needs, input, improve, prog...\n",
       "4         [Investigate, suspicious, activity, account]\n",
       "Name: subject, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_spam['subject'].head().apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 72)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(analyzer = process_text)\n",
    "my_spam_bow = cv.fit_transform(my_spam['subject'])\n",
    "\n",
    "# get shape of spam_bow\n",
    "my_spam_bow.shape\n",
    "#print(my_spam_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_my_spam = classifier.predict(my_spam_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
